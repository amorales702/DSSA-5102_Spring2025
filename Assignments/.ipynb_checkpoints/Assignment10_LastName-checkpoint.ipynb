{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9da05e",
   "metadata": {},
   "source": [
    "# Assignment #10 - Data Gathering and Warehousing - DSSA-5102\n",
    "\n",
    "Instructor: Melissa Laurino</br>\n",
    "Spring 2025</br>\n",
    "\n",
    "Name:\n",
    "</br>\n",
    "Date: \n",
    "<br>\n",
    "<br>\n",
    "**At this time in the semester:** <br>\n",
    "- We have explored a dataset. <br>\n",
    "- We have cleaned our dataset. <br>\n",
    "- We created a Github account with a repository for this class and included a metadata read me file about our data. <br>\n",
    "- We introduced general SQL syntax, queries, and applications in Python.<br>\n",
    "- Created our own databases from scratch using MySQL Workbench and Python with SQLAlchemy on our local server and locally on our machine.\n",
    "- Populated our databases with the data we cleaned at the start of the semester.\n",
    "- Created a visual enhanced entity relationship diagram for our database\n",
    "<br>\n",
    "\n",
    "**Objective**: Connect to a website using an API. Gather live data from a website using an API.<br>\n",
    "<br>\n",
    "**iNaturalist**: iNaturalist is a community of citizen scientists that encourages accurate data collection and species identification of the natural world. \n",
    "<br>\n",
    "No observations of captive plants or animals should be included in the iNaturalist data. Research grade observaitons have been verified by the community in terms of species ID, location, etc. Research grade observations have been verified by the community of experts in that field. \n",
    "<br>\n",
    "API's are useful to bridge the gap between manually querying and downloading data, and then uploading them into Python, by just working with the live data directly in your platform of choice.\n",
    "\n",
    "Follow the instructions below to complete the assignment. Answer any questions in markdown cell boxes. Be sure to comment all code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0bb90",
   "metadata": {},
   "source": [
    "Learn more about the iNaturalist API here: https://api.inaturalist.org/v1/docs/#!/Observations/get_observations_observers<br><br>\n",
    "\n",
    "Python libraries for working with iNaturalist API to gather live data:<br>\n",
    "pyinaturalist: https://github.com/pyinat/pyinaturalist <br>\n",
    "Tips for writing ChatGPT prompts with the iNaturalist API: https://forum.inaturalist.org/t/inaturalists-api-python-and-chatgpt/59202/9 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd8cf8",
   "metadata": {},
   "source": [
    "## Part 1 - Accessing iNaturalist data via API from scratch: (10)\n",
    "<br>\n",
    "Why is this important? - If you are accessing data that is private, not public, you will need to generate a token. <br>\n",
    "<br>\n",
    "**Obtaining an iNaturalist API token:** <br>\n",
    "Create a username and password and **log in** to www.inaturalist.org using those credentials.<br>\n",
    "In the same browser, obtain your INaturalist API Token by using this link: https://www.inaturalist.org/users/api_token<br>\n",
    "Do not click this link more than once or it will regenerate your token!<br>\n",
    "With iNaturalist, this token is <b>ONLY<b> valid for 24hrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the requests library\n",
    "import requests\n",
    "\n",
    "# Additional libraries needed for this first section:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ccde6-61bd-46de-8b94-c0ed7004122c",
   "metadata": {},
   "source": [
    "The requests library: https://pypi.org/project/requests/ <br>\n",
    "This will allow us to make HTTP requests to the iNaturalist API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e8f03-210d-4614-81c6-5cc31b9e818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After obtaining an API Token above by following the instructions above, copy and paste it here:\n",
    "API_TOKEN = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4576b7-29f5-4906-ab9e-9799eafb80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the request headers with the token.\n",
    "# The bearer tells the API that you are an authenticated user.\n",
    "# The f ensures it is being read as a string - look inside the parenthesis and replace them with the actual values\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "# Define a base URL (This is given to us in the iNaturalist API instructions\n",
    "url = \"https://api.inaturalist.org/v1/observations\"\n",
    "\n",
    "# Define the base URL for iNaturalist API without manually setting parameters below this is our query selecting for all observations for the user_login=melissalaurino\n",
    "# url = \"https://api.inaturalist.org/v1/observations/observers?user_login=melissalaurino\"\n",
    "\n",
    "# Retrieve specified user observations (with privacy controls)\n",
    "params = {\n",
    "    \"user_id\": \"datagatheringandwarehousing\",  #This is a class example account that I had made, or you can use my username: melissalaurino\n",
    "    \"per_page\": 10,\n",
    "    \"order_by\": \"observed_on\",\n",
    "    \"order\": \"desc\"\n",
    "}\n",
    "\n",
    "# Make a GET request to retrieve observations with headers\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "# Parse the JSON response by checking if it was successful and printing our results\n",
    "\n",
    "# Check if the request was successful (HTTP status 200 = OK)\n",
    "if response.status_code == 200:\n",
    "    #.json() will result in a python dictionary\n",
    "    data = response.json()\n",
    "    #Print the number of observation returned, the id, the species_guess and the observed_on date\n",
    "    print(f\"Retrieved {len(data['results'])} observations:\")\n",
    "    for obs in data['results']:\n",
    "        print(f\"ID: {obs['id']}, Species: {obs.get('species_guess')}, Date: {obs.get('observed_on')}\")\n",
    "else:\n",
    "    # If the above code does not work, print the error message if the request failed.\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "    # If you get an error, is the token you are using new in the last 24hrs? Is it your most recent generated token?\n",
    "\n",
    "print(\"Successfully retrieved data using the iNaturalist API!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbcff0-4240-45ab-bdda-db575ffa28ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e78819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When calling the data through the API, it returns everything since we did not specify what we wanted.\n",
    "# For this example, this is fine because I know that the user @datagatheringandwarehousing only has three observations.\n",
    "\n",
    "# Extract the fields we want into a list of dictionaries\n",
    "observations = []\n",
    "for obs in data[\"results\"]: # This creates a list of .json objects\n",
    "    observations.append({\n",
    "        \"id\": obs[\"id\"],\n",
    "        \"species\": obs.get(\"species_guess\"),\n",
    "        \"observed_on\": obs.get(\"observed_on\"),\n",
    "        \"place\": obs.get(\"place_guess\"),\n",
    "        \"user\": obs[\"user\"][\"login\"] if obs.get(\"user\") else None\n",
    "    })\n",
    "\n",
    "# Convert to rows via pandas, our data frame\n",
    "data = pd.DataFrame(observations)\n",
    "\n",
    "# Save to .csv\n",
    "data.to_csv(\"API_observations.csv\", index=False) # Remember that the index would number the rows which we do not need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00c590-d82a-4063-b7e6-9664596ef5fd",
   "metadata": {},
   "source": [
    "Python could have packages that do this automatically for you. The R package jsonlite can take the .json output and automatically convert it to a .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly check iNaturalist API for connection:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c412d",
   "metadata": {},
   "source": [
    "You can continue to explore your new API connection created from scratch, or continue to steps below. These are the beginning steps to aquire live social media data for a database. The iNaturalist API can be added to websites, databases, apps, and R shiny applications using the API reference application to create an app_id, and app_secret. \n",
    "https://www.inaturalist.org/pages/api+reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03226bd",
   "metadata": {},
   "source": [
    "## Part 2 - Accessing iNaturalist data through library API (10)\n",
    "\n",
    "When it comes to Python (and R), there are many libraries already created by users that save you the time while connecting to an API by connecting with libraries or apps instead. This way, you do not need to obtain your own access token, define endpoints, or URLs, because you are using a package or an app that has already completed that process. We will continue with iNaturalst for this example. \n",
    "\n",
    "**Python:** <br>\n",
    "pyiNaturalist (https://pypi.org/project/pyinaturalist/0.12.0/) <br>\n",
    "<br>\n",
    "**R:** <br>\n",
    "**spocc** (https://cran.r-project.org/web/packages/spocc/spocc.pdf) - A programmatic interface to many species occurrence data sources,including Global Biodiversity Information Facility ('GBIF'), 'iNaturalist',\n",
    "'eBird', Ocean 'Biogeographic' Information System ('OBIS'), and many more! <br>\n",
    "**rinat** (https://cran.r-project.org/web/packages/rinat/rinat.pdf) - A programmatic interface to the API provided by the 'iNaturalist' website to download species occurrence data submitted by citizen scientists. <br>\n",
    "**iNatTools** - Outdated and may not work with current versions of R, but resources online using iNatTools may relate to the packages above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284902ff-df1e-4343-bb3d-523c2e869f1b",
   "metadata": {},
   "source": [
    "Install pyiNaturalist for Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69087f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install pyinaturalist in your Jupyter Notebook, run the following line:\n",
    "# !pip install pyinaturalist\n",
    "# Comment out this code after you have it downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e324d145-3d66-4450-a735-77a44ada7e9c",
   "metadata": {},
   "source": [
    "Here is a link to all definitions in the fields: https://api.inaturalist.org/v1/docs/#/Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3196f-813b-4d70-87d3-da58c663c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyinaturalist.node_api import get_observations # Get observations\n",
    "from pyinaturalist.node_api import get_taxa # Search through observation taxa\n",
    "import time # Pauses API requests\n",
    "import mysql.connector # Connecting to our database\n",
    "from sqlalchemy import create_engine, text # Database navigation with Jupyter notebook\n",
    "import json # I really hope you do not need this! I had a lot of issues working with the json data at first. My final product does NOT use this.\n",
    "import matplotlib.pyplot as plt # Quick graphing and visualization\n",
    "import seaborn as sns # Quick graphing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa027a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 observations of Harbor Porpoise in the Year 2024\n",
    "# These names are \"phrase\" sensitive\n",
    "response = get_observations(taxon_name='Atlantic Harbour Porpoise', year = 2024, per_page=5)\n",
    "\n",
    "# Print the species, the date, and the location:\n",
    "for result in response['results']:\n",
    "    print(f\"Species: {result.get('species_guess')} | Date: {result.get('observed_on')} | Location: {result.get('place_guess')}\")\n",
    "\n",
    "# Another option would be to search via the taxon_id obtained from the iNaturalist URL for Harbour Porpoise:\n",
    "#41440 - is the id for Harbor Porpoise, Phocoena phocoena\n",
    "#623433 is the id for ATLANTIC Harbor Porpoise, Phocoena phocoena phocoena specifically\n",
    "# Selecting for a more specific species would change your results! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d714c-b4a5-4ac0-a945-051728c79b25",
   "metadata": {},
   "source": [
    "For a list of all iNaturalist metadata and deinfitions, visit: https://www.inaturalist.org/terminology <br>\n",
    "\n",
    "To obtain Species taxon ID numbers (More accurate than relying on common names), search the species name and obtain the taxon ID from the URL: https://www.inaturalist.org/observations (The same instructions apply to the place ID too)\n",
    "\n",
    "For a list of all functions and options in the observations, we can ask for help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59b637-3a08-4390-9407-8898f2dc5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(get_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c9d72-67f3-4c2f-98aa-98ccfc9a0222",
   "metadata": {},
   "source": [
    "Really cool sample data available on Github! : https://github.com/pyinat/pyinaturalist/tree/main/examples/sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c16fb2-51c2-4ab2-8e8e-a633feeade93",
   "metadata": {},
   "source": [
    "Obtain all observations of New Jersey's largest native species of moth, the Cecropia Moth, in the year 2024:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5647f3f-7a5f-49b8-83bb-da8b6d630819",
   "metadata": {},
   "source": [
    "![PICTURE](moth.png) \n",
    "Observation from Stockton University: https://www.inaturalist.org/observations/163097321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters we want to obtain the Cecropia Moth in New Jersey in the year 2024:\n",
    "params = {\n",
    "    'taxon_id': 81582,     # Cecropia Moth (Instructions to obtain ID's above)\n",
    "    'place_id': 51,        # New Jersey (Instructions to obtain ID's above)\n",
    "    'year': 2024,\n",
    "    'per_page': 100        # 100 results per request/page\n",
    "        }\n",
    "\n",
    "all_obs = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"Getting_observations page {page}...\")\n",
    "    response = get_observations(**params, page=page)\n",
    "    results = response.get('results', [])\n",
    "\n",
    "    if not results:\n",
    "        print(\"No more observations.\")\n",
    "        break\n",
    "\n",
    "    for obs in results:\n",
    "        obs_id = obs.get('id')\n",
    "        all_obs.append({\n",
    "            'id': obs_id,\n",
    "            'species': obs.get('species_guess'),\n",
    "            'observed_on': obs.get('observed_on'),\n",
    "            'place': obs.get('place_guess'),\n",
    "            'user': obs['user']['login'] if obs.get('user') else None,\n",
    "            'latitude': obs['geojson']['coordinates'][1] if obs.get('geojson') else None,\n",
    "            'longitude': obs['geojson']['coordinates'][0] if obs.get('geojson') else None,\n",
    "            'url': f\"https://www.inaturalist.org/observations/{obs_id}\"  # ✅ Add observation link\n",
    "        })\n",
    "\n",
    "    page += 1      # For every 100 observations, form a new page. A new page will form when checking for additional observations too.\n",
    "                   # There needs to be no observations in a page to continue to the next step of the loop.\n",
    "    time.sleep(1)  # Be nice to the iNaturalist API connection! I am lucky because I picked a species that I know is rare and does not have\n",
    "                   # many observations. Without prior background knowledge, this is good to do. The time.sleep() enforces a pause.\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(all_obs) # Convert to data frame\n",
    "print(f\"\\nTotal Cecropia Moth observations collected: {len(df)}\") # Print the length of the data frame\n",
    "\n",
    "df.to_csv(\"cecropia_moth_2024_NJ.csv\", index=False) # Use pandas to save as .csv file\n",
    "print(\"Saved to cecropia_moth_2024_NJ.csv\") # Confirm .csv file saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e49a9-8e39-48d2-8bbc-49e608ac516a",
   "metadata": {},
   "source": [
    "**STOP HERE**<br>\n",
    "- Ensure your .csv file is populated. It will be saved in the same working directory THIS file is in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8230f2",
   "metadata": {},
   "source": [
    "No matter how you are using the iNaturalist API, you have a DOWNLOAD limit. <br>\n",
    "60 requests per minute (or about 1 request per second) <br>\n",
    "Max results per_page are 200 results per request (pyinaturalist defaults to per_page=30) <br>\n",
    "To avoid getting denied requests with the API:\n",
    "- Use time.sleep(1) between requests\n",
    "- For species with a lot of data, use per_page requests of 100-200\n",
    "- Consider subsetting for large datasets by place_id or year!\n",
    "<br><br>\n",
    "Let's try a real life approach below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3522b",
   "metadata": {},
   "source": [
    "## Part 3 - Applying our knowledge to a real world problem! (30)\n",
    "\n",
    "## Case Study: **Northern Diamondback Terrapins** (_Malaclemys terrapin terrapin_)\n",
    "\n",
    "Background information:<br>Diamondback terrapins are New Jersey's only species of brackish water turtle. Brackish water has a mixture of both salt water and fresh water. They are commonly found in the back bays and saltmarshes of New Jersey. They can be found from Massachusetts to North Carolina. The females come ashore to nest in the summer months, while the males will not leave the water at all. Coming ashore to nest has consequences and risks for this species that include human-caused mortalities from vehicle strikes and natural predation. Although the males do not leave the water, human-caused mortality due to crab pots and ghost gear remain a huge threat to both sexes for this species of special concern. Up until 2016, terrapins were hunted during their winter hibernation for terrapin soup! <br>\n",
    "To further the concern for New Jersey's Diamondback terrapin, the species has temperature-dependent sex determination. Studies from research institutes and rehabilitation facilities, like Stockton University, have shown captive eggs that are incubated at a low temperature will produce all male terrapins and captive eggs that are incubated at a high temperature will produce all female terrapins. It is hypothesized that the determination of sexes may only vary by just a few degrees. If this is the case, how will the threat of climate change and the warming salt marshes impact our local population?<br><br>\n",
    "**Note:** New Jersey's subspecies of terrapin is the NORTHERN Diamondback Terrapin (_Malaclemys terrapin terrapin_) or (_Genus species subspecies_). We want to make sure we are selecting for the taxon_id of the NORTHERN Diamondback Terrapin. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d7933",
   "metadata": {},
   "source": [
    "### You are a data scientist for a wildlife contracting company, ML Wildlife. \n",
    "\n",
    "### ML Wildlife Mission Statement: To pioneer innovative approaches to wildlife management and policy-making through data collection, storage, and analysis. It is the company's goal to create sustainable connections between human activities and the natural world to preserve biodiversity.\n",
    "\n",
    "#### In a New Jersey town (that will remain unnamed), there was a proposal to begin construction during the Summer of 2024 on a bike path that will run for 2.5 miles through the salt marsh. The construction has been delayed for one year and is expected to begin in the Summer of 2025. The bike path will be a raised (7ft) concrete pathway, or seawall, to accomodate for high and low tides to ensure that flooding is not an issue for the path. Water or wildlife (Turtles, fish, crabs, inverts, etc.) can not pass through or under the pathway. Birds can fly over the pathway. Construction is estimated to last four months. The goal of the pathway is to teach people about wildlife by walking through the man-made salt marsh trail. Railings will be placed on either side of the pathway to ensure human safety, but what about the safety of the wildlife?\n",
    "\n",
    "#### Local environmentalists and biologists are concerned with the proposed bike path, especially for the state's Diamondback terrapin population. Will this bike path create an obstacle that will force more females to cross the roads to lay their eggs? What about the eggs that are laid along the bike bath already from the year before? Will the nests be ruined in the process? In addition to the Diamondback terrapin, additional species also utilize this area for nesting and feeding like the Ipswich Sparrow, which is a subspecies of the Savannah Sparrow that has a very limited range. The saltmarsh serves as an important nursery ground for Atlantic Menhaden, the Mid-Atlantic ecosystem's \"Most Important Fish of the Sea.\"\n",
    "\n",
    "Your job is to:<br>\n",
    "- Collect citizen science observations from 2020-2024 in iNaturalist of the Northern Diamondback terrapin using the iNaturalist API with python package, ipyNaturalist.<br>\n",
    "- Upload that data into a database either locally or on your MySQL server. <br>\n",
    "- Use SQL to: <br>\n",
    "    ----Select for research grade observations only in New Jersey. We only want observations that have been accepted by expert naturalists or scientists that confirm the observation, if the API has not already selected for this.<br>\n",
    "    ----Determine the best time of year (Or months or weeks or time of day) for project construction.<br>\n",
    "    ----Determine what subset of the population (Egg, Juvennile or Adult) you believe would be most impacted during construction and the structure itself. <br>\n",
    "    ----Explore two other species that inhabit and utilize the saltmarsh (Examples are the Ipswich sparrow, Seaside sparrow, Saltmarsh sparrow, Atlantic menhaden, or the Mud fiddler crab and Eastern Mud snail (What terrapins eat) and hypothesize how they would be impacted by this construction project after you have explored their data. Use the data from these other two species to support your decision below. If you would like to choose another species you can, just be mindful of iNaturalist API limits. I recommend looking at the iNaturalist website and explore the different species before collecting data that you do not need. <br>\n",
    "\n",
    "**For your submission**\n",
    "- Post your final assignment to your Github repository for this class (You may need to create a folder for just this assignment) and submit the link as the Blackboard submission.\n",
    "- As a data scientists, provide your overall determination approving or disproving the project with at least three visualizations to go along with the queried SQL data and briefly state why. Use the queries above to support your case. Practice good data visualization.\n",
    "- You do not have to go into too much biology detail and there is no right or wrong answer!<br>\n",
    "- State two possible reasons for error in your data.\n",
    "- You can write this submission as a Word doc if you prefer, but all files needed to complete the assignment should be on your Github repository. \n",
    "<br><br>\n",
    "Also note, this is a **mostly** \"fictional\" case study :). <br>\n",
    "\n",
    "**Background information on the other species:**<br>\n",
    "Ipswich Sparrow (_Passerculus sandwichensis princeps_) - A subspecies of the Savannah Sparrow. Subspecies can breed independently of the parent species. These birds feed directly in the dunes and saltmarshes. They are not as common as the parent species.<br>\n",
    "Atlantic Menhaden (_Brevoortia tyrannus_) - A small schooling bait fish less than 10in in length. These fish begin their lives in the back bays and salt marshes. They are the primary food source for many species of marine mammals, birds, sharks, and larger fish. They are harvested commercially by us humans in the Mid-Atlantic to create fertilizer, fish oil, pet food, lip products and many other uses.<br>\n",
    "Eastern Mud Snail (_Ilyanassa obsoleta_) - Food source to many species of birds and terrapins. The ocean clean up crew - feeds on detritis and other matter. <br>\n",
    "Mud fiddler crab (_Minuca pugnax_) - Only found on the East Coast of the United States. Like many other animals, it is thought this species is expanding the Northern range due to climate change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d400d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages if starting from scratch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8eb73",
   "metadata": {},
   "source": [
    "How many different species of terrapins were documented worldwide on iNaturalist in the year 2024? Our results show there are 8 different species/subspecies of terrapins documented on iNaturalist worldwide in 2024. _Malaclemys terrapin terrapin_ are the species we want because they inhabit our area. Ensure you are collecting the correct data by selecting for the correct species!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e1fbc",
   "metadata": {},
   "source": [
    "**To obtain a taxon_id for any species or a place_id from iNaturalist:** <br>\n",
    "--Log in to the account you created <br>\n",
    "--Hit Explore tab at the top <br>\n",
    "--Search for ANY species you would like (In our case, it's Northern Diamondback Terrapin)<br>\n",
    "--The taxon_id for the species is found in the URL: https://www.inaturalist.org/observations?place_id=any&subview=map&**taxon_id=39838**\n",
    "<br>\n",
    "--More information on the different attributes you can use to filter the data: https://www.inaturalist.org/pages/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa variables for functions and other background information:\n",
    "#terrapin = 39838\n",
    "taxon_id = 39838  #Northern Diamondback Terrapin (NDBT) species ID obtained from the URL following instructions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3602ae0",
   "metadata": {},
   "source": [
    "Breaking down the iNaturalist.org URL:<br>\n",
    "<br>\n",
    "<br>\n",
    "The API call: <br>\n",
    "\"https://api.inaturalist.org/v1/observations?....<br><br>\n",
    "\n",
    "taxon_id=\", taxon_id, \"& #I have supplied the taxon ID above for NDBT, but feel free to adjust or explore others to help answer your objectives.<br><br>\n",
    "\n",
    "place_id=any& #Observation IDs are for ANYWHERE in the world. I specifically chose NDBT because I know they only exist from Massachusetts to North Carolina. So I know I will not be getting millions of rows of data because it is a species with a limited geography.<br>\n",
    "<br>\n",
    "\n",
    "d1=2020-01-01& #The date you are collecting observations from. 2020-Present. Earlier dates will take longer processing times. <br>\n",
    "<br>\n",
    "\n",
    "per_page=200& #The number of results per query. **NOTE** The iNaturalist API ONLY allows for 200 records at a time. This is why we have a function below to loop every 200 observations.\n",
    "<br>\n",
    "<br>\n",
    "order_by=id& #Order by species id\n",
    "<br>\n",
    "<br>\n",
    "order=asc& #Ascending order\n",
    "<br>\n",
    "<br>\n",
    "id_above=0\"<br><br>\n",
    "\n",
    "**A detailed explanation on these parameters can be found here: https://www.inaturalist.org/pages/search+urls**\n",
    "\n",
    "Listing multiple taxon ID's:\n",
    "https://www.inaturalist.org/observations?place_id=any&taxon_ids=85553,26039,47113\n",
    "\n",
    "Multiple taxa using a List (Define your list beforehand).\n",
    "\n",
    "You can use lists on iNaturalist to restrict a search to a set of taxa. For example, https://www.inaturalist.org/lists/111820-Chicago-Wilderness-Region-Spring-Wildflowers is a list that is already set up.\n",
    "\n",
    "Sort by Dates or Randomly\n",
    "\n",
    "The Identify Filters panel already has options built in to sort by Date Added (default), Date Observed, Date Updated (edited), Faves, or Random. Sorting options are Descending (default) or Ascending.\n",
    "\n",
    "Two of these options are not available in the Explore filters, but can still be added manually: Date Updated and Random. To add these, use\n",
    "\n",
    "    order_by=updated_at\n",
    "    order_by=random\n",
    "\n",
    "Sorting order is specified by\n",
    "\n",
    "    order=desc or\n",
    "    order=asc\n",
    "\n",
    "Annotations\n",
    "\n",
    "term_id= - the annotation group\n",
    "\n",
    "    1=Life Stage, 9=Sex, 12=Plant Phenology, 17=Alive or Dead\n",
    "\n",
    "term_value_id= - the value within the group\n",
    "\n",
    "    Life Stage: 2=Adult, 3=Teneral, 4=Pupa, 5=Nymph, 6=Larva, 7=Egg, 8=Juvenile, 16=Subimago\n",
    "    Sex: 10=Female, 11=Male\n",
    "    Plant Phenology: 13=Flowering, 14=Fruiting, 15=Flower Budding, 21=No Evidence of Flowering\n",
    "    Alive or Dead: 18=Alive, 19=Dead, 20=Cannot Be Determined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c72f5-6989-48ad-adb8-1de89f12f990",
   "metadata": {},
   "source": [
    "#### Write a function to obtain the observations needed for analysis and our database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf9f9e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7553a966-7414-408d-8271-f0fac20c23d3",
   "metadata": {},
   "source": [
    "### **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f6b85-8f86-4254-b21b-1495250c40f3",
   "metadata": {},
   "source": [
    "#### Create a database for your data\n",
    "Try to put your SQL skills to the test and create your own database in MySQL Workbench! <br>\n",
    "My SQL script is attached. This is what I did, but feel free to complete this the way you feel most comfortable! <br>\n",
    "I used a MySQL Workbench query script to :\n",
    "- Create the database\n",
    "- Create two tables\n",
    "- Populate two tables\n",
    "- Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a5986-58eb-423d-b528-dc69cbed3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MySQL Workbench database that you just created!\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='!',\n",
    "    database=''\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"Connected successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8ffb9",
   "metadata": {},
   "source": [
    "**STOP** <br>\n",
    "- Remember that SQL does not work well with periods in column names or uppercase letters. Make sure your column headers do not have periods and are not in all capital letters.\n",
    "- Whether you created your database locally or on a server, double check the file has been created.\n",
    "- Don't forget to recycle your code you worked so hard to complete for Assignment #7-#8 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7eecc",
   "metadata": {},
   "source": [
    "By this point, all of our data is loaded into a database with a method of your choosing. Use a combination of SQL queries to explore the questions noted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0734d2c-05bb-4691-b871-e5e3ef98a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = \"\"\n",
    "\n",
    "# Create the engine and test the connection\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1d8e4",
   "metadata": {},
   "source": [
    "#### Determine the locations of the Northern Diamondback Terrapins observations. We are only interested in New Jersey observations for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4b6d4-0b37-43af-a877-ea8590b4b516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "677a496a",
   "metadata": {},
   "source": [
    "#### What life stage will be most impacted by the construction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c04a1-09dc-4cae-91ec-6221fdb79009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93d33510",
   "metadata": {},
   "source": [
    "#### What time of year are we seeing the most terrapins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370035c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd58c5d4-5255-4d34-b189-5e1fa0fc2eaf",
   "metadata": {},
   "source": [
    "#### Create your additional graphs and explore different species of the salt marsh :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8a4f7-9d4d-4827-b6d4-56811facd7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
